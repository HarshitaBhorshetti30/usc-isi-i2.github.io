<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DIG: Entity Extractors</title>
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
	<link rel="stylesheet" href="css/index.css">
	<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
	<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
	<!--[if lt IE 9]>
		<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
		<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
	<![endif]-->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-62418606-1', 'auto');
		ga('send', 'pageview');
	</script>
</head>
<body>
	<nav class="navbar navbar-default navbar-inverse navbar-fixed-top">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#nav-links">
					<span class="sr-only">Toggle navigation</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="navbar-brand scroll" href="http://usc-isi-i2.github.io/dig/"><img src="img/dig.png" height="20" alt="DIG: Domain-specific Insight Graphs"></a>
			</div><!-- navbar-header -->
			<div class="collapse navbar-collapse" id="nav-links">
				<ul class="nav navbar-nav navbar-right">
					<li class="active"><a class="scroll" href="#home">Home</a></li>
					<li><a class="scroll" href="#slides">Slides</a></li>
					<li><a class="scroll" href="#about">About</a></li>
					<li><a class="scroll" href="#tutorial">Tutorial</a></li>
					<!--<li><a class="scroll" href="#pub">Publications</a></li>-->
					<li><a class="scroll" href="#people">People</a></li>
				</ul>        
			</div><!-- collapse navbar-collapse -->
		</div><!-- container -->
	</nav>

	<header id="home">
		<div class="container">
			<h1>Entity Extractors</h1>
			<h2>For Domain-Specific Insight Graphs</h2>
			<h2>Easily extract features from free text using Mechanical Turk</h2>
			<div class="affiliation">
				<div><a href="../"><img src="img/iig-logo.png" width="280"></a></div>
				<div><a href="http://www.isi.edu"><img src="img/isi-logo.png" width="250"></a></div>
				<div><a href="http://www.usc.edu"><img src="img/usc-shield-name-white.png"></a></div>
			</div>
		</div><!-- container -->
		<div class="scroll-btn-container hidden-xs">
			<a class="scroll-btn scroll" href="#slides"><i class="fa fa-angle-down"></i></a>
		</div>
	</header>
	
	<section id="slides">
		<div class="content">
			<div class="slides-wrapper">
				<iframe src="https://www.haikudeck.com/e/QGvSJbOOiZ/?isUrlHashEnabled=false&isPreviewEnabled=false&isHeaderVisible=false" width="640" height="541" frameborder="0" marginheight="0" marginwidth="0"></iframe><br/><span style="font-family: arial, sans-serif; font-size: 8pt;"><a title="Entity Extractors In One Hour Presentation" href="https://www.haikudeck.com/p/QGvSJbOOiZ/entity-extractors-in-one-hour?utm_campaign=embed&utm_source=webapp&utm_medium=text-link">Entity Extractors In One Hour</a> - Created with Haiku Deck, presentation software that inspires</span>
			</div>
		</div>
	</section>

	<section id="about" class="container">
		<h2>WHAT IS ENTITY EXTRACTOR?</h2>
		<div class="content">
			<p>tbd</p>
			<img src="img/entity-extractors.jpg" width="700">
		</div>
	</section>

	<section id="tutorial" class="container">
		<h2>TUTORIAL: HOW TO USE THE TOOL</h2>
		
		<div class="content">
			<h3>ABOUT MTURK</h3>
				<p>MTurk hits can be run in sandbox (developer) or live environment. Hits can be created with/without qualifications. All the possibilities are explained below.</p>
			<h4>REQUIREMENTS</h4>
			<ol>
				<li>Git, GitHub acct. $GITHUB.</li>
				<li>Install python 2.7, java 1.7, maven 3 using system installers (apt-get, yum, Mac installer, etc.).
				<li>Install <a href="https://github.com/usc-isi-i2/Web-Karma">Web-Karma</a>, <a href="https://github.com/usc-isi-i2/dig-mturk">dig-mturk</a> in your github repository root folder.</li>
				<li>Install following python libraries:</li>
				<ul>
					<li><code>pip install requests</code></li>
					<li><code>pip install boto</code></li>
					<li><code>pip install nltk</code></li>
					<li><code>pip install awscli</code></li>
				<ul>
			</ol>
			<h4>ENVIRONMENT</h4>
			<ol>
				<li>Your home directory is $HOME.</li>
				<li>You will want to edit your shell init file, typically <code>~/.bashrc</code>, <code>~/.profile</code>, or <code>~/.bash_profile</code>
				<li>Edit (at the bottom will work well) shell init file to contain the following:</li>
					<p><code>export GITHUB=&lt;your github repository root folder&gt;</code></p> 
					<p><code>export PATH="$PATH:$GITHUB/dig-mturk/generic/scripts"</code></p>
				<li><code>source &lt;shell init file&gt;</code></li>
				<li><code>cd $GITHUB/dig-mturk; git checkout master; cd mturk; mvn clean install</code></li>
				<li><code>cd $GITHUB/Web-Karma; git checkout development; mvn clean install</code></li>
				<li>To configure for Amazon AWS, you will need an account with AWS username, AWS Access Key Id, and AWS Secret Access Key; and an Amazon S3 bucket that is writable using those credentials.</li>
				<li>(At ISI you can obtain this information from <a href="http://www.isi.edu/~philpot/">Andrew</a> or <a href="https://www.linkedin.com/in/subessware">Suba</a>)</li>
				<li><code>aws configure</code></li>
				<ul>
					<li>AWS Access Key ID = key id obtained</li>
					<li>AWS Secret Access Key = secret key obtained</li>
					<li>Default region name = usc-west-2</li>
					<li>Default output format = json</li>
				</ul>
				<li>Create $HOME/.aws/mturk_live.properties with contents:</li>
					<p><code>
						# -------------------<br/>
						# ADVANCED PROPERTIES<br/>
						# -------------------<br/>
						# If you want to have your solution work against the Amazon Mechnical Turk Production site (http://www.mturk.com)<br/>
						# use the service_url defined below:<br/>
						service_url=https://mechanicalturk.amazonaws.com/?Service=AWSMechanicalTurkRequester<br/><br/>

						#list of comma separated retriable errors which will be retried by RetryFilter<br/>
						retriable_errors=Server.ServiceUnavailable<br/>
						retry_attempts=10<br/>
						retry_delay_millis=1000<br/>
						access_key=&lt;AWS ACCESS KEY ID&gt;<br/>
						secret_key=&lt;AWS SECRET ACCESS KEY&gt;
					</code></p>
				<li>Create $HOME/.aws/mturk_sandbox.properties with contents:</li>
					<p><code>
						# -------------------<br/>
						# ADVANCED PROPERTIES<br/>
						# -------------------<br/>
						# If you want to test your solution in the Amazon Mechanical Turk Developers Sandbox (http://sandbox.mturk.com)<br/>
						# use the service_url defined below:<br/>
  						service_url=https://mechanicalturk.sandbox.amazonaws.com/?Service=AWSMechanicalTurkRequester<br/><br/>

						#list of comma separated retriable errors which will be retried by RetryFilter<br/>
						retriable_errors=Server.ServiceUnavailable<br/>
						retry_attempts=10<br/>
						retry_delay_millis=1000<br/>
						access_key=&lt;AWS ACCESS_KEY ID&gt;<br/>
						secret_key=&lt;AWS SECRET ACCESS KEY&gt;<br/>
					</code></p>
			</ol>
			<h4>SETUP A NEW EXTRACTION</h4>			
			<h3>ABOUT MTURK</h3>
				<p>MTurk hits can be run in sandbox (developer) or live environment. Hits can be created with/without qualifications. All the possibilities are explained below.</p>
			<h4>SETUP</h4>
			<ol>
				<li><code>cd $GITHUB/dig-mturk</code></li>
				<li>Determine the name of the extraction. Examples are 'eyehair' and 'ethnic' (no spaces, lower case).</li>
				<li>For convenience, <code>export EXTRACTION=&lt;extraction&gt;</code></li>
				<li><code>newExtraction.sh $EXTRACTION</code> This will create <code>$GITHUB/dig-mturk/extractions/$EXTRACTION</code> and copy/adapt a few files from <code>$GITHUB/dig-mturk/extractions/boilerplate/</code> to <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/</code>:</li>
				<ul>
					<li>create.cfg</li>
					<li>hitdata.pyfmt</li>
					<li>head.html, instructions.html, tail.html</li>
					<li>$EXTRACTION-context.json, $EXTRACTION-model.png, $EXTRACTION-model.ttl, $EXTRACTION-report.md</li>
					<li>qualification/*</li>
					<li>karma/</li>
				</ul>
				<li>Edit these configuration files. You will want a small set of categories and associated labels. The category name itself should be a simple lower case identifier without punctuation. The label can be rendered in English. For example, for an extraction <code>eyehair</code> we might have categories <code>eye</code>, with human-readable label <code>Eye Color</code>; and <code>hair</code>, with label <code>Hair Type</code>.</li>

				<ul>
					<li>create.cfg: Edit as desired number of hits, number of sentences to be used.  If your data comes from ElasticSearch, the search path is very important to verify.</li>

					<li>hitdata.pyfmt: Edit the task description, title, and categories. You should leave the <code>scratch_category</code> as it is. You may wish to edit the keywords. You should leave the bracketed expressions <code>{instructions}</code>, <code>{qualifications}</code> and <code>{sentences}</code> as they are.</li>

					<li>sentence data:</li>
					<ul>
					<li>If you are providing sentence data from a plain text file, edit <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/sentences.txt</code> to contain the sentence data, one sentence per line.</li>
					<li>If you are obtaining sentence data from an ElasticSearch index, edit <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/fetchSentences.sh</code> and/or <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/query.json</code> to specify the index name, desired hit count, credentials, query fields, and query path.  Then execute the script:<br/><code>fetchSentences.sh $EXTRACTION $TRIAL $SIZE</code> where $SIZE is the number of sentences to be fetched from ES. This will generate <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/sentences.json.</li>

					</ul>

					<br/>The files <code>head.html</code>, <code>instructions.html</code>, and <code>tail.html</code> will be combined to become an instructions page for the users.<br/>
					<li><code>head.html</code>: no change.</li>
					<li><code>instructions.html</code>: Change the sample content and the categories to conform to your categories and likely data. There are five necessary modifications in <code>instructions.html</code>. Each is introduced by a comment suggesting what needs to be changed.</li>
					<li><code>tail.html</code>: Change the <code>tail.html</code> if you consider the standard boilerplate text confusing in context when presented to a user as part of the instructions.</li>
					<li>You can inspect the look of the instructions by performing: <code>cat head.html instructions.html tail.html > page.html; open page.html</code></li>

					</li>
					<li>head.html: no change.</li>
					<li>instructions.html: change the sample content and the categories to conform to your categories and likely data. There are five necessary modifications in instructions.html. Each is introduced by a comment suggesting what needs to be changed.</li>
					<li>tail.html: change the tail.html if you consider the boilerplate text confusing in context.</li>
					<li>you can inspect the look of the instructions by performing: <code>cat head.html instructions.html tail.html > page.html; open page.html</code></li>

					<li>karma: We need to instruct the Karma information integration system how to interpret the categories and labels we chose above, when processing the results.<br/>
					  <ol>
					  <li>Edit <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/karma/preloaded-ontologies/mturk-ontology.ttl</code>: Define the categories as relations (see embedded example) and use the labels as the <code>rdfs:label</code>.</li>
					  <li>Edit <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/karma/python/mturk.py</code>: In the definition of data structure <code>categoryToAnnotationClass</code> at the top of the file, insert a mapping between your categories and their labels.</li>
					  </ol>


				</ul>
					<li>fetchSentences.sh, query.json</li>
				</ul>
				<ul>


					<li>qualification/*</li>


				</ul>
			</ol>
			
			<h4>GENERATE QUALIFICATION TASK</h4>
			<p>The Qualification Task is a small test where the user practice the hit before do the paid one. The objective of the test is teach the user by practicing, so for each wrong answer the user receives a feedback with the explanation of how to correctly answer it. The user just can do the real hit after be approved in the Qualification Task, and the test can be done several times of after a delay (defined for the test).</p>
			<ol>
				<li>If an extraction requires qualification, it has to be generated before creating hits. To generate a qualification task, you need the following:</li>
				<li>Name of your qualification. Typically, we name the qualification the same as the extraction it supports.  So herein we will use <code>$EXTRACTION</code> as the name of the qualification.</li>
				<li>Categories for this extraction.</li> 
				<li>Example sentences.</li>
				<li>The answers for those sentences.</li>
				<li>Explanations of the answers (used to provide feedback during qualification testing).</li>
			</ol>
			<h4>Steps to create qualification:</h4>
			<ol>
				<li><code>newQualification.sh $EXTRACTION</code>- this will copy config JSON from <code>$GITHUB/dig-mturk/extractions/boilerplate/qualification/</code> to <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/qualification/qual_${EXTRACTION}.json.</code>   It will also generate qualification.cfg.</li>
				<li>Edit <code>qual_${EXTRACTION}.json</code> to reflect categories, sentences, answers, etc. to define your qualification domain. The JSON key <code>explanation.wrong</code> needn't be edited. The script will populate this field as required before generating HTML.</li>
				<li>Edit <code>qualification.cfg</code> to reflect your organization name, Amazon S3 bucket name, Amazon access_key_id and Amazon secret_access_key.</li>
				<li>The JSON key <code>explanation.wrong</code> needn't be edited. The py script will populate this field as required before generating HTML. Edit the fields above to define your qualification domain:</li>
				<ol>
					<li>categories [label]: put the name of the attributes that should be selected</li>
					<li>total-questions: set the total number of questions in the test</li>
					<li>correct-questions: set the number of questions that the user have to do correctly to be approved</li>
					<li>title: change the company's name </li>
					<li>subtitle: change the categories names</li>
					<li>average-time: average time that a regular user spend to finish the test</li>
					<li>help [title]: change the categories names</li>
					<li>help [html]: paste a html code with the explanation/image that helps the user to figure out the correct way to select the words for this domain</li>
					<li>aprove-message [html]: change the number for the number of correct question that the user have to answer</li>
				</ol>
				<p>For each sentence, change:</p>
				<ol>
					<li>id: should be in increasing order</li>
					<li>text: the complete sentence that should be analized</li>
					<li>annotations: set "yes" if there are selections to be done in the sentence and "no" if there is no word to select in the text</li>
					<li>select: specify which categories should be selected in this question (can be all the categories or just one. For more than one, put each categories separated by comma.</li>
					<li>answer [category]: for each category, get all the words that should be selected. If there is more than one, put the answers separated for \t. If there is no answer for this category, set as "".</li>
					<li>explanation [wrong] [text]: write the explanation for why the sentence have to be selected like you specified in the answer. This text just will be shown when the user selects a wrong answer for the question.</li>
				</ol>
				<li><code>newQualification.sh $EXTRACTION</code>- this will copy config JSON from extractions/boilerplate/qualification/ to extractions/$EXTRACTION/qualification/qual_${EXTRACTION}.json</li>
				<li><code>generateQualification.sh $EXTRACTION --publish --upload</code>. This will generate and publish the qualification page HTML and assets to Amazon S3.</li>
				<li><code>generateQualification.sh $EXTRACTION --render</code> (optional) can be used to preview the qualification test sentences and correction essages (message presented to user after incorrect response).</li>
				<li>Deploy qualification to MTurk:</li>
				<ul>
					<li><code>./deployQualification.sh -sandbox $GITHUB/dig-mturk/extractions/$EXTRACTION/qualification.cfg</code> to create qualification in sandbox. This will update qualification.cfg with the qualification ID generated by Amazon for sandbox trials of the qualification test.</li>
					<li><code>./deployQualification.sh -live $GITHUB/dig-mturk/extractions/$EXTRACTION/qualification.cfg</code> to create qualification in live. This will update qualification.cfg with the qualification ID generated by Amazon for live use by any interested Turkers.</li>
				</ul>
				<li>Create a cron job that executes <code>$GITHUB/dig-mturk/mturk/src/main/python/respondQualification.py</code> for every 5 minutes. This job approves/rejects all qualification requests.</li>
			</ol>
			<h4>SANDBOX DRY RUN</h4>
			<p>You may want to edit <code>$GITHUB/dig-mturk/extractions/$EXTRACTION/create.cfg</code> for a small number of hits, small number of sentences/hit.</p>
			<ol>
				<li>For sandbox, choose a trial name (e.g., trial01, sandbox01). For convenience <code>export TRIAL=&lt;trial&gt;</code></li>
				<li><code>mkdir $GITHUB/dig-mturk/extractions/$EXTRACTION/$TRIAL</code></li>
				<li><code>createHits.sh sandbox $EXTRACTION $TRIAL</code>. This will create config json for hits and upload it to S3 at extractions/$EXTRACTION/$TRAIL/config/.</li>
				<li><code>deployHits.sh -sandbox $EXTRACTION $TRIAL</code>. This will create all files requires to create a HIT and publish those to extractions/$EXTRACTION/$TRAIL/hits/ in S3 and yield a few sandbox URLs, which you can annotate yourself to test things out. If hit was created using qualification you need to take the qualification test, get qualified before you are allowed to do the hits.</li>
				<li>When you are satisfied with the look/feel and complete at least 3 sandbox tests on the same hit, <code>hitResults.sh -sandbox $EXTRACTION $TRIAL</code>. This will approve the unapproved assignments of the hits and create tab separated result files in S3 (extractions/$EXTRACTION/$TRAIL/hits/).</li>
			</ol>
			<h4>LIVE SCALE RUN</h4>
			<p>You may want to edit create.cfg for a significant number of hits, standardized number of sentences/hit.</p>
			<ol>
				<li>For live, choose a trial name (e.g., trial01, live01). If you want the sandbox hits to be reserved use a different trial name. For convenience <code>export TRIAL=&lt;trial&gt;</code></li>
				<li><code>mkdir $GITHUB/dig-mturk/extractions/$EXTRACTION/$TRIAL</code></li>
				<li><code>createHits.sh $EXTRACTION $TRIAL</code>. This will create config json for hits and upload it to S3 at extractions/$EXTRACTION/$TRAIL/config/.</li>
				<li><code>deployHits.sh -live $EXTRACTION $TRIAL</code>. This will create all files requires to create a HIT and publish those to extractions/$EXTRACTION/$TRAIL/hits/ in S3 and yield a few sandbox URLs, which you can annotate yourself to test things out. If hit was created using qualification you need to take the qualification test, get qualified before you are allowed to do the hits.</li>
				<li>The progress of hits can be monitored in the requester interface. When a significant number of assignments have been completed, <code>hitResults.sh -live $EXTRACTION $TRIAL</code>. This will create all files requires to create a HIT and publish those to extractions/$EXTRACTION/$TRAIL/hits/ in S3 and yield a few sandbox URLs, which you can annotate yourself to test things out. If hit was created using qualification you need to take the qualification test, get qualified before you are allowed to do the hits.</li>
			</ol>
			<h4>AFTER PUBLISHING HITS (common steps for both live and sandbox)</h4>
			<p>Since these are processing done on results fetched from hits and stored in S3, these steps don't depend on the staging area (live/sandbox) of the hits.</p>
			<ol>
				<li><code>consolidateResults.sh $EXTRACTION $TRIAL</code># Note: no -sandbox since it is independent of Mturk. This will consolidate the result files for all hits in a particular trial.</li>
				<li><code>fetchConsolidated.sh $EXTRACTION $TRIAL</code>. This will download consolidated result file from S3.</li>
				<li><code>modelConsolidated.sh $EXTRACTION $TRIAL</code>. This will do offline karma model for the results fetched from S3.</li>
				<li><code>adjudicate.sh $EXTRACTION $TRIAL</code>. This will compute the agreement amongst the Turkers for each annotation. Adjudicated results are in $GITHUB/dig-mturk/extractions/$EXTRACTION/$TRIAL/adjudicated_$EXTRACTION_$TRIAL.json</li>
				<li>adjudicated_$EXTRACTION_$TRIAL.json can be used to TRAIN the CRF.</li>
				<li>TBD: apply trained CRF++ extractor to data.</li>
				<li>TBD: karma model for CRF++ extracted data.</li>
				<li>TBD: integrate karma mode for CRF++.</li>
				<li>wget --no-check-certificate <a href="https://drive.google.com/uc?id=0B4y35FiV1wh7QVR6VXJ5dWExSTQ">https://drive.google.com/uc?id=0B4y35FiV1wh7QVR6VXJ5dWExSTQ</a> -O crfpp-0.58.tgz</li>
			</ol>
		</div>
	</section>
	<!--
	<section id="pub" class="container">
		<h2>PUBLICATIONS</h2>
		<ul class="content list-unstyled">
			<li>
				<div class="title"><a href="http://www.isi.edu/integration/papers/knoblock15-spie.pdf">A Scalable Architecture for Extracting, Aligning, Linking, and Visualizing Multi-Int Data</a></div>
				<div class="author">Knoblock, C. A. and Szekely, P.</div>
				<div class="location">In Proceedings of the Conference on the Next Generation Analyst III, 2015. SPIE, 9499</div>
			</li>
			<li>
				<div class="title"><a href="http://www.forbes.com/sites/thomasbrewster/2015/04/17/darpa-nasa-and-partners-show-off-memex">Watch Out Google, DARPA Just Open Sourced All This Swish 'Dark Web' Search Tech</a></div>
				<div class="author">Forbes</div>
			</li>
                       <li>
				<div class="title"><a href="http://www.wired.co.uk/news/archive/2015-05/19/human-trafficking-data-hack">The escort database that combats human trafficking</a></div>
				<div class="author">wired.co.uk</div>
			</li>
		</ul>
	</section>
	-->
	<section id="people" class="container">
		<h2>PEOPLE</h2>
		<ul class="content list-unstyled">
			<li>
				<a style="background-image:url('img/people/Pedro-Szekely.jpg')" href="../szekely"></a>
				<div class="description">
					<div class="name">Pedro Szekely</div>
					<div class="title">Project Leader & Research Associate Professor</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Craig-Knoblock.jpg')" href="../knoblock"></a>
				<div class="description">
					<div class="name">Craig Knoblock</div>
					<div class="title">Director & Research Professor</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Kevin-Knight.jpg')" href="http://www.isi.edu/~knight"></a>
				<div class="description">
					<div class="name">Kevin Knight</div>
					<div class="title">Director & Professor</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Daniel-Marcu.jpg')" href="http://www.isi.edu/~marcu"></a>
				<div class="description">
					<div class="name">Daniel Marcu</div>
					<div class="title">Director & Research Associate Professor</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Andrew-Philpot.jpg')" href="http://www.isi.edu/~philpot/"></a>
				<div class="description">
					<div class="name">Andrew G. Philpot</div>
					<div class="title">Computer Scientist</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Subessware-S-K.jpg')" href="https://www.linkedin.com/in/subessware"></a>
				<div class="description">
					<div class="name">Subessware S K</div>
					<div class="title">Student</div>
				</div>
			</li>
			<li>
				<a style="background-image:url('img/people/Lidia-Ferreira.jpg')" href="http://homepages.dcc.ufmg.br/~lidiaferreira/indexen.html"></a>
				<div class="description">
					<div class="name">Lidia Ferreira <sup>1</sup></div>
					<div class="title">Student</div>
					<!--test-->
				</div>
			</li>
		</ul>
	</section>

	<section class="container">
		<h2>ACKNOWLEDGMENT</h2>
		<p class="content">This research is supported by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL) under contract number FA8750-14-C-0240.</p>
		<p class="content"><sup>1</sup> The student Lidia Ferreira thank to Science Without Borders Program, CAPES Scholarship - Proc. Nº 88888.030514/2013-00.</p>
	</section>

	<footer>
		<div class="container">&copy; 2015 The University of Southern California</div>
	</footer>

	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.2/js/bootstrap.min.js"></script>
	<script src="js/index.js"></script>
</body>
</html>
